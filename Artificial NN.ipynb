{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3bef5cb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ccc36d35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7a5228db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x70baaf62ba50>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(42)  # for reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "79417574",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv('/home/darshan39/Downloads/fashionmnist/fashion-mnist_train.csv')\n",
    "df2 = pd.read_csv('/home/darshan39/Downloads/fashionmnist/fashion-mnist_test.csv')\n",
    "df = pd.concat([df1, df2], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6677765a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 70000 entries, 0 to 69999\n",
      "Columns: 785 entries, label to pixel784\n",
      "dtypes: int64(785)\n",
      "memory usage: 419.2 MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b9235c4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df.iloc[:, 1:].values\n",
    "y = df.iloc[:, 0].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "01da2c8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fd3ddb29",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.astype(\"float32\") / 255.0\n",
    "x_test = x_test.astype(\"float32\") / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b9035700",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]], shape=(56000, 784), dtype=float32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "db69dd6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FashionMNISTDataset(Dataset):\n",
    "\n",
    "    def __init__(self, features, labels):\n",
    "        self.features = torch.tensor(features, dtype=torch.float32)\n",
    "        self.labels = torch.tensor(labels, dtype=torch.long)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.features)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.features[idx], self.labels[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b7ff0d01",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = FashionMNISTDataset(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "081fb816",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0039, 0.0000,\n",
       "         0.0510, 0.4627, 0.1843, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0275,\n",
       "         0.0000, 0.2510, 0.7529, 0.6235, 0.8118, 0.7333, 0.7922, 0.7137, 0.5451,\n",
       "         0.4510, 0.4118, 0.0000, 0.0000, 0.0039, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.5804, 0.7255, 0.4471, 0.8784, 0.8471, 0.7882, 0.7804,\n",
       "         0.8078, 0.8275, 0.7961, 0.0118, 0.0000, 0.0118, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0039, 0.0000, 0.0000, 0.6157, 0.7373, 0.4863, 0.8196, 0.8431, 0.7804,\n",
       "         0.7451, 0.7412, 0.7176, 0.8000, 0.1412, 0.0000, 0.0157, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0039, 0.0000, 0.0000, 0.0627, 0.4353, 1.0000, 1.0000,\n",
       "         0.7333, 0.8078, 0.7686, 0.7765, 0.7490, 0.0863, 0.0000, 0.0078, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0039, 0.0000, 0.0000, 0.0000, 0.0118,\n",
       "         0.0275, 0.0000, 0.1373, 0.8784, 0.8118, 0.3765, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0039, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0353, 0.8235, 0.8824, 0.6000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0118, 0.0000, 0.0039,\n",
       "         0.0039, 0.0196, 0.0157, 0.0000, 0.0667, 0.8824, 0.8941, 0.7608, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0039, 0.0000, 0.0000,\n",
       "         0.0000, 0.0039, 0.0000, 0.0039, 0.0000, 0.0000, 0.8824, 0.8510, 0.8392,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0039, 0.0000, 0.0000, 0.8902, 0.8941,\n",
       "         0.9647, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0039, 0.0000, 0.0000, 1.0000,\n",
       "         0.9059, 0.9059, 0.1882, 0.5294, 0.2941, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0039, 0.0000, 0.0000, 0.0000,\n",
       "         0.7961, 0.7137, 0.7059, 0.8667, 1.0000, 0.2941, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0863,\n",
       "         0.5725, 0.7569, 0.6902, 0.7451, 0.7294, 0.8157, 0.1373, 0.0039, 0.0000,\n",
       "         0.0039, 0.0039, 0.0000, 0.0000, 0.0039, 0.0118, 0.0196, 0.0078, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.5451,\n",
       "         1.0000, 1.0000, 0.8353, 0.8118, 0.7373, 0.7020, 0.8745, 0.0941, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0039, 0.0078, 0.0118, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0078, 0.0000, 0.0000, 0.0000, 0.2118, 0.7373,\n",
       "         0.8627, 0.6784, 0.0000, 0.4745, 0.8667, 0.7098, 0.7333, 0.8824, 0.0588,\n",
       "         0.0000, 0.0039, 0.0078, 0.0000, 0.0000, 0.0000, 0.0000, 0.0667, 0.6627,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.3255, 0.8314,\n",
       "         0.7725, 0.2078, 0.0000, 0.0000, 0.5961, 0.8588, 0.7451, 0.7373, 0.9020,\n",
       "         0.0431, 0.0000, 0.0039, 0.0000, 0.0000, 0.0000, 0.0549, 0.4353, 0.5725,\n",
       "         0.8627, 0.3725, 0.0000, 0.0078, 0.0000, 0.0000, 0.0000, 0.3804, 0.8706,\n",
       "         0.7020, 0.0078, 0.0000, 0.0000, 0.0000, 0.6431, 0.8745, 0.7569, 0.7686,\n",
       "         0.8745, 0.0118, 0.0000, 0.0157, 0.0000, 0.0000, 0.5529, 0.6039, 0.3922,\n",
       "         0.1412, 0.7020, 0.8902, 0.0000, 0.0000, 0.0000, 0.0000, 0.3412, 0.8902,\n",
       "         0.6941, 0.0000, 0.0000, 0.0078, 0.0000, 0.0000, 0.6824, 0.8118, 0.7647,\n",
       "         0.7725, 0.8745, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.4667, 0.1882,\n",
       "         0.8000, 0.1137, 0.5569, 1.0000, 0.0000, 0.0000, 0.0000, 0.2902, 0.8784,\n",
       "         0.7098, 0.0275, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.7176, 0.8118,\n",
       "         0.7686, 0.7843, 0.8510, 0.0000, 0.0000, 0.0000, 0.1020, 0.1961, 0.3176,\n",
       "         0.2902, 0.4510, 0.7804, 0.7529, 0.9176, 0.2784, 0.0000, 0.3137, 0.8745,\n",
       "         0.7059, 0.0118, 0.0000, 0.0039, 0.0000, 0.0039, 0.0000, 0.0000, 0.7137,\n",
       "         0.8078, 0.7608, 0.7882, 0.8314, 0.0000, 0.3255, 0.6196, 0.5647, 0.4980,\n",
       "         0.5961, 0.8667, 0.8431, 0.8471, 0.8118, 0.7804, 0.4784, 0.6549, 0.9255,\n",
       "         0.7059, 0.0000, 0.0000, 0.0078, 0.0000, 0.0000, 0.0039, 0.0000, 0.0000,\n",
       "         0.7176, 0.7843, 0.7373, 0.7725, 0.7647, 0.0000, 0.1020, 0.4471, 0.6392,\n",
       "         0.7373, 0.8353, 0.8000, 0.8275, 0.9059, 0.8863, 0.8157, 0.8549, 1.0000,\n",
       "         0.6314, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0039, 0.0000,\n",
       "         0.0000, 0.9255, 0.8314, 0.7882, 0.8314, 0.9176, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.1686, 0.3176, 0.3765, 0.4353, 0.4039, 0.3176,\n",
       "         0.0471, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0039,\n",
       "         0.0000, 0.0000, 0.4431, 0.4039, 0.3725, 0.4431, 0.4039, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000]),\n",
       " tensor(5))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "06f5393d",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = FashionMNISTDataset(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f45b3efb",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, pin_memory=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ff579bc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class myNN(nn.Module):\n",
    "    def __init__(self, num_features):\n",
    "        super(myNN, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(num_features, 128),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=0.3),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=0.3),\n",
    "            nn.Linear(64, 10)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8daccbf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.1\n",
    "num_epochs = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1d30f997",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = myNN(x_train.shape[1])\n",
    "model.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr=learning_rate, weight_decay=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1a71bcd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/100], Loss: 0.6093\n",
      "Epoch [2/100], Loss: 0.4797\n",
      "Epoch [3/100], Loss: 0.4424\n",
      "Epoch [4/100], Loss: 0.4237\n",
      "Epoch [5/100], Loss: 0.4085\n",
      "Epoch [6/100], Loss: 0.3961\n",
      "Epoch [7/100], Loss: 0.3863\n",
      "Epoch [8/100], Loss: 0.3777\n",
      "Epoch [9/100], Loss: 0.3696\n",
      "Epoch [10/100], Loss: 0.3607\n",
      "Epoch [11/100], Loss: 0.3570\n",
      "Epoch [12/100], Loss: 0.3515\n",
      "Epoch [13/100], Loss: 0.3466\n",
      "Epoch [14/100], Loss: 0.3451\n",
      "Epoch [15/100], Loss: 0.3405\n",
      "Epoch [16/100], Loss: 0.3380\n",
      "Epoch [17/100], Loss: 0.3356\n",
      "Epoch [18/100], Loss: 0.3361\n",
      "Epoch [19/100], Loss: 0.3306\n",
      "Epoch [20/100], Loss: 0.3303\n",
      "Epoch [21/100], Loss: 0.3248\n",
      "Epoch [22/100], Loss: 0.3253\n",
      "Epoch [23/100], Loss: 0.3188\n",
      "Epoch [24/100], Loss: 0.3157\n",
      "Epoch [25/100], Loss: 0.3157\n",
      "Epoch [26/100], Loss: 0.3150\n",
      "Epoch [27/100], Loss: 0.3103\n",
      "Epoch [28/100], Loss: 0.3111\n",
      "Epoch [29/100], Loss: 0.3060\n",
      "Epoch [30/100], Loss: 0.3082\n",
      "Epoch [31/100], Loss: 0.3031\n",
      "Epoch [32/100], Loss: 0.3045\n",
      "Epoch [33/100], Loss: 0.3014\n",
      "Epoch [34/100], Loss: 0.3023\n",
      "Epoch [35/100], Loss: 0.3006\n",
      "Epoch [36/100], Loss: 0.2970\n",
      "Epoch [37/100], Loss: 0.2986\n",
      "Epoch [38/100], Loss: 0.2944\n",
      "Epoch [39/100], Loss: 0.2985\n",
      "Epoch [40/100], Loss: 0.2931\n",
      "Epoch [41/100], Loss: 0.2934\n",
      "Epoch [42/100], Loss: 0.2940\n",
      "Epoch [43/100], Loss: 0.2913\n",
      "Epoch [44/100], Loss: 0.2937\n",
      "Epoch [45/100], Loss: 0.2902\n",
      "Epoch [46/100], Loss: 0.2896\n",
      "Epoch [47/100], Loss: 0.2860\n",
      "Epoch [48/100], Loss: 0.2871\n",
      "Epoch [49/100], Loss: 0.2854\n",
      "Epoch [50/100], Loss: 0.2883\n",
      "Epoch [51/100], Loss: 0.2872\n",
      "Epoch [52/100], Loss: 0.2831\n",
      "Epoch [53/100], Loss: 0.2871\n",
      "Epoch [54/100], Loss: 0.2810\n",
      "Epoch [55/100], Loss: 0.2820\n",
      "Epoch [56/100], Loss: 0.2857\n",
      "Epoch [57/100], Loss: 0.2799\n",
      "Epoch [58/100], Loss: 0.2829\n",
      "Epoch [59/100], Loss: 0.2786\n",
      "Epoch [60/100], Loss: 0.2816\n",
      "Epoch [61/100], Loss: 0.2796\n",
      "Epoch [62/100], Loss: 0.2814\n",
      "Epoch [63/100], Loss: 0.2821\n",
      "Epoch [64/100], Loss: 0.2757\n",
      "Epoch [65/100], Loss: 0.2779\n",
      "Epoch [66/100], Loss: 0.2764\n",
      "Epoch [67/100], Loss: 0.2741\n",
      "Epoch [68/100], Loss: 0.2748\n",
      "Epoch [69/100], Loss: 0.2770\n",
      "Epoch [70/100], Loss: 0.2744\n",
      "Epoch [71/100], Loss: 0.2737\n",
      "Epoch [72/100], Loss: 0.2750\n",
      "Epoch [73/100], Loss: 0.2731\n",
      "Epoch [74/100], Loss: 0.2751\n",
      "Epoch [75/100], Loss: 0.2747\n",
      "Epoch [76/100], Loss: 0.2723\n",
      "Epoch [77/100], Loss: 0.2717\n",
      "Epoch [78/100], Loss: 0.2721\n",
      "Epoch [79/100], Loss: 0.2714\n",
      "Epoch [80/100], Loss: 0.2732\n",
      "Epoch [81/100], Loss: 0.2686\n",
      "Epoch [82/100], Loss: 0.2696\n",
      "Epoch [83/100], Loss: 0.2690\n",
      "Epoch [84/100], Loss: 0.2712\n",
      "Epoch [85/100], Loss: 0.2671\n",
      "Epoch [86/100], Loss: 0.2722\n",
      "Epoch [87/100], Loss: 0.2664\n",
      "Epoch [88/100], Loss: 0.2659\n",
      "Epoch [89/100], Loss: 0.2705\n",
      "Epoch [90/100], Loss: 0.2700\n",
      "Epoch [91/100], Loss: 0.2708\n",
      "Epoch [92/100], Loss: 0.2704\n",
      "Epoch [93/100], Loss: 0.2695\n",
      "Epoch [94/100], Loss: 0.2667\n",
      "Epoch [95/100], Loss: 0.2688\n",
      "Epoch [96/100], Loss: 0.2677\n",
      "Epoch [97/100], Loss: 0.2693\n",
      "Epoch [98/100], Loss: 0.2632\n",
      "Epoch [99/100], Loss: 0.2656\n",
      "Epoch [100/100], Loss: 0.2673\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "\n",
    "    total_epoch_loss = 0\n",
    "\n",
    "    for batch_features, batch_labels in train_loader:\n",
    "\n",
    "\n",
    "        batch_features, batch_labels = batch_features.to(device), batch_labels.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(batch_features)\n",
    "\n",
    "\n",
    "        loss = criterion(outputs, batch_labels)\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        total_epoch_loss += loss.item()\n",
    "    \n",
    "    avg_epoch_loss = total_epoch_loss / len(train_loader)\n",
    "    \n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {avg_epoch_loss:.4f}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "48109188",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9411964285714286\n"
     ]
    }
   ],
   "source": [
    "# Evaluation on train set\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for batch_features, batch_labels in train_loader:\n",
    "        batch_features, batch_labels = batch_features.to(device), batch_labels.to(device)\n",
    "        outputs = model(batch_features)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += batch_labels.shape[0]\n",
    "        correct += (predicted == batch_labels).sum().item()\n",
    "\n",
    "    accuracy = correct / total\n",
    "    print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8f24daf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8925714285714286\n"
     ]
    }
   ],
   "source": [
    "# Evaluation on test set\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for batch_features, batch_labels in test_loader:\n",
    "        batch_features, batch_labels = batch_features.to(device), batch_labels.to(device)\n",
    "        outputs = model(batch_features)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += batch_labels.shape[0]\n",
    "        correct += (predicted == batch_labels).sum().item()\n",
    "\n",
    "    accuracy = correct / total\n",
    "    print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b4f6def",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
