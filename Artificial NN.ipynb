{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3bef5cb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ccc36d35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7a5228db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x78eb48737a50>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(42)  # for reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "79417574",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv('/home/darshan39/Downloads/fashionmnist/fashion-mnist_train.csv')\n",
    "df2 = pd.read_csv('/home/darshan39/Downloads/fashionmnist/fashion-mnist_test.csv')\n",
    "df = pd.concat([df1, df2], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6677765a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 70000 entries, 0 to 69999\n",
      "Columns: 785 entries, label to pixel784\n",
      "dtypes: int64(785)\n",
      "memory usage: 419.2 MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b9235c4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df.iloc[:, 1:].values\n",
    "y = df.iloc[:, 0].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "01da2c8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fd3ddb29",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.astype(\"float32\") / 255.0\n",
    "x_test = x_test.astype(\"float32\") / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b9035700",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]], shape=(56000, 784), dtype=float32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "db69dd6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FashionMNISTDataset(Dataset):\n",
    "\n",
    "    def __init__(self, features, labels):\n",
    "        self.features = torch.tensor(features, dtype=torch.float32)\n",
    "        self.labels = torch.tensor(labels, dtype=torch.long)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.features)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.features[idx], self.labels[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b7ff0d01",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = FashionMNISTDataset(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "081fb816",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0039, 0.0000,\n",
       "         0.0510, 0.4627, 0.1843, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0275,\n",
       "         0.0000, 0.2510, 0.7529, 0.6235, 0.8118, 0.7333, 0.7922, 0.7137, 0.5451,\n",
       "         0.4510, 0.4118, 0.0000, 0.0000, 0.0039, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.5804, 0.7255, 0.4471, 0.8784, 0.8471, 0.7882, 0.7804,\n",
       "         0.8078, 0.8275, 0.7961, 0.0118, 0.0000, 0.0118, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0039, 0.0000, 0.0000, 0.6157, 0.7373, 0.4863, 0.8196, 0.8431, 0.7804,\n",
       "         0.7451, 0.7412, 0.7176, 0.8000, 0.1412, 0.0000, 0.0157, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0039, 0.0000, 0.0000, 0.0627, 0.4353, 1.0000, 1.0000,\n",
       "         0.7333, 0.8078, 0.7686, 0.7765, 0.7490, 0.0863, 0.0000, 0.0078, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0039, 0.0000, 0.0000, 0.0000, 0.0118,\n",
       "         0.0275, 0.0000, 0.1373, 0.8784, 0.8118, 0.3765, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0039, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0353, 0.8235, 0.8824, 0.6000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0118, 0.0000, 0.0039,\n",
       "         0.0039, 0.0196, 0.0157, 0.0000, 0.0667, 0.8824, 0.8941, 0.7608, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0039, 0.0000, 0.0000,\n",
       "         0.0000, 0.0039, 0.0000, 0.0039, 0.0000, 0.0000, 0.8824, 0.8510, 0.8392,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0039, 0.0000, 0.0000, 0.8902, 0.8941,\n",
       "         0.9647, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0039, 0.0000, 0.0000, 1.0000,\n",
       "         0.9059, 0.9059, 0.1882, 0.5294, 0.2941, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0039, 0.0000, 0.0000, 0.0000,\n",
       "         0.7961, 0.7137, 0.7059, 0.8667, 1.0000, 0.2941, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0863,\n",
       "         0.5725, 0.7569, 0.6902, 0.7451, 0.7294, 0.8157, 0.1373, 0.0039, 0.0000,\n",
       "         0.0039, 0.0039, 0.0000, 0.0000, 0.0039, 0.0118, 0.0196, 0.0078, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.5451,\n",
       "         1.0000, 1.0000, 0.8353, 0.8118, 0.7373, 0.7020, 0.8745, 0.0941, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0039, 0.0078, 0.0118, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0078, 0.0000, 0.0000, 0.0000, 0.2118, 0.7373,\n",
       "         0.8627, 0.6784, 0.0000, 0.4745, 0.8667, 0.7098, 0.7333, 0.8824, 0.0588,\n",
       "         0.0000, 0.0039, 0.0078, 0.0000, 0.0000, 0.0000, 0.0000, 0.0667, 0.6627,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.3255, 0.8314,\n",
       "         0.7725, 0.2078, 0.0000, 0.0000, 0.5961, 0.8588, 0.7451, 0.7373, 0.9020,\n",
       "         0.0431, 0.0000, 0.0039, 0.0000, 0.0000, 0.0000, 0.0549, 0.4353, 0.5725,\n",
       "         0.8627, 0.3725, 0.0000, 0.0078, 0.0000, 0.0000, 0.0000, 0.3804, 0.8706,\n",
       "         0.7020, 0.0078, 0.0000, 0.0000, 0.0000, 0.6431, 0.8745, 0.7569, 0.7686,\n",
       "         0.8745, 0.0118, 0.0000, 0.0157, 0.0000, 0.0000, 0.5529, 0.6039, 0.3922,\n",
       "         0.1412, 0.7020, 0.8902, 0.0000, 0.0000, 0.0000, 0.0000, 0.3412, 0.8902,\n",
       "         0.6941, 0.0000, 0.0000, 0.0078, 0.0000, 0.0000, 0.6824, 0.8118, 0.7647,\n",
       "         0.7725, 0.8745, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.4667, 0.1882,\n",
       "         0.8000, 0.1137, 0.5569, 1.0000, 0.0000, 0.0000, 0.0000, 0.2902, 0.8784,\n",
       "         0.7098, 0.0275, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.7176, 0.8118,\n",
       "         0.7686, 0.7843, 0.8510, 0.0000, 0.0000, 0.0000, 0.1020, 0.1961, 0.3176,\n",
       "         0.2902, 0.4510, 0.7804, 0.7529, 0.9176, 0.2784, 0.0000, 0.3137, 0.8745,\n",
       "         0.7059, 0.0118, 0.0000, 0.0039, 0.0000, 0.0039, 0.0000, 0.0000, 0.7137,\n",
       "         0.8078, 0.7608, 0.7882, 0.8314, 0.0000, 0.3255, 0.6196, 0.5647, 0.4980,\n",
       "         0.5961, 0.8667, 0.8431, 0.8471, 0.8118, 0.7804, 0.4784, 0.6549, 0.9255,\n",
       "         0.7059, 0.0000, 0.0000, 0.0078, 0.0000, 0.0000, 0.0039, 0.0000, 0.0000,\n",
       "         0.7176, 0.7843, 0.7373, 0.7725, 0.7647, 0.0000, 0.1020, 0.4471, 0.6392,\n",
       "         0.7373, 0.8353, 0.8000, 0.8275, 0.9059, 0.8863, 0.8157, 0.8549, 1.0000,\n",
       "         0.6314, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0039, 0.0000,\n",
       "         0.0000, 0.9255, 0.8314, 0.7882, 0.8314, 0.9176, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.1686, 0.3176, 0.3765, 0.4353, 0.4039, 0.3176,\n",
       "         0.0471, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0039,\n",
       "         0.0000, 0.0000, 0.4431, 0.4039, 0.3725, 0.4431, 0.4039, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000]),\n",
       " tensor(5))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "06f5393d",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = FashionMNISTDataset(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f45b3efb",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, pin_memory=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ff579bc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class myNN(nn.Module):\n",
    "    def __init__(self, num_features):\n",
    "        super(myNN, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(num_features, 128),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=0.3),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=0.3),\n",
    "            nn.Linear(64, 10)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8daccbf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.1\n",
    "num_epochs = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1d30f997",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = myNN(x_train.shape[1])\n",
    "model.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr=learning_rate, weight_decay=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1a71bcd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/100], Loss: 0.2854\n",
      "Epoch [2/100], Loss: 0.2799\n",
      "Epoch [3/100], Loss: 0.2777\n",
      "Epoch [4/100], Loss: 0.2808\n",
      "Epoch [5/100], Loss: 0.2781\n",
      "Epoch [6/100], Loss: 0.2777\n",
      "Epoch [7/100], Loss: 0.2768\n",
      "Epoch [8/100], Loss: 0.2785\n",
      "Epoch [9/100], Loss: 0.2774\n",
      "Epoch [10/100], Loss: 0.2780\n",
      "Epoch [11/100], Loss: 0.2749\n",
      "Epoch [12/100], Loss: 0.2723\n",
      "Epoch [13/100], Loss: 0.2750\n",
      "Epoch [14/100], Loss: 0.2693\n",
      "Epoch [15/100], Loss: 0.2713\n",
      "Epoch [16/100], Loss: 0.2695\n",
      "Epoch [17/100], Loss: 0.2721\n",
      "Epoch [18/100], Loss: 0.2723\n",
      "Epoch [19/100], Loss: 0.2705\n",
      "Epoch [20/100], Loss: 0.2712\n",
      "Epoch [21/100], Loss: 0.2715\n",
      "Epoch [22/100], Loss: 0.2670\n",
      "Epoch [23/100], Loss: 0.2675\n",
      "Epoch [24/100], Loss: 0.2711\n",
      "Epoch [25/100], Loss: 0.2705\n",
      "Epoch [26/100], Loss: 0.2683\n",
      "Epoch [27/100], Loss: 0.2720\n",
      "Epoch [28/100], Loss: 0.2687\n",
      "Epoch [29/100], Loss: 0.2661\n",
      "Epoch [30/100], Loss: 0.2654\n",
      "Epoch [31/100], Loss: 0.2689\n",
      "Epoch [32/100], Loss: 0.2677\n",
      "Epoch [33/100], Loss: 0.2674\n",
      "Epoch [34/100], Loss: 0.2676\n",
      "Epoch [35/100], Loss: 0.2682\n",
      "Epoch [36/100], Loss: 0.2646\n",
      "Epoch [37/100], Loss: 0.2674\n",
      "Epoch [38/100], Loss: 0.2696\n",
      "Epoch [39/100], Loss: 0.2630\n",
      "Epoch [40/100], Loss: 0.2655\n",
      "Epoch [41/100], Loss: 0.2655\n",
      "Epoch [42/100], Loss: 0.2653\n",
      "Epoch [43/100], Loss: 0.2665\n",
      "Epoch [44/100], Loss: 0.2640\n",
      "Epoch [45/100], Loss: 0.2642\n",
      "Epoch [46/100], Loss: 0.2647\n",
      "Epoch [47/100], Loss: 0.2668\n",
      "Epoch [48/100], Loss: 0.2629\n",
      "Epoch [49/100], Loss: 0.2654\n",
      "Epoch [50/100], Loss: 0.2614\n",
      "Epoch [51/100], Loss: 0.2613\n",
      "Epoch [52/100], Loss: 0.2643\n",
      "Epoch [53/100], Loss: 0.2577\n",
      "Epoch [54/100], Loss: 0.2618\n",
      "Epoch [55/100], Loss: 0.2646\n",
      "Epoch [56/100], Loss: 0.2619\n",
      "Epoch [57/100], Loss: 0.2635\n",
      "Epoch [58/100], Loss: 0.2608\n",
      "Epoch [59/100], Loss: 0.2615\n",
      "Epoch [60/100], Loss: 0.2606\n",
      "Epoch [61/100], Loss: 0.2595\n",
      "Epoch [62/100], Loss: 0.2624\n",
      "Epoch [63/100], Loss: 0.2609\n",
      "Epoch [64/100], Loss: 0.2610\n",
      "Epoch [65/100], Loss: 0.2623\n",
      "Epoch [66/100], Loss: 0.2613\n",
      "Epoch [67/100], Loss: 0.2612\n",
      "Epoch [68/100], Loss: 0.2608\n",
      "Epoch [69/100], Loss: 0.2597\n",
      "Epoch [70/100], Loss: 0.2586\n",
      "Epoch [71/100], Loss: 0.2618\n",
      "Epoch [72/100], Loss: 0.2614\n",
      "Epoch [73/100], Loss: 0.2608\n",
      "Epoch [74/100], Loss: 0.2566\n",
      "Epoch [75/100], Loss: 0.2590\n",
      "Epoch [76/100], Loss: 0.2614\n",
      "Epoch [77/100], Loss: 0.2595\n",
      "Epoch [78/100], Loss: 0.2561\n",
      "Epoch [79/100], Loss: 0.2602\n",
      "Epoch [80/100], Loss: 0.2564\n",
      "Epoch [81/100], Loss: 0.2627\n",
      "Epoch [82/100], Loss: 0.2591\n",
      "Epoch [83/100], Loss: 0.2585\n",
      "Epoch [84/100], Loss: 0.2562\n",
      "Epoch [85/100], Loss: 0.2610\n",
      "Epoch [86/100], Loss: 0.2568\n",
      "Epoch [87/100], Loss: 0.2585\n",
      "Epoch [88/100], Loss: 0.2562\n",
      "Epoch [89/100], Loss: 0.2512\n",
      "Epoch [90/100], Loss: 0.2597\n",
      "Epoch [91/100], Loss: 0.2548\n",
      "Epoch [92/100], Loss: 0.2581\n",
      "Epoch [93/100], Loss: 0.2560\n",
      "Epoch [94/100], Loss: 0.2581\n",
      "Epoch [95/100], Loss: 0.2565\n",
      "Epoch [96/100], Loss: 0.2597\n",
      "Epoch [97/100], Loss: 0.2558\n",
      "Epoch [98/100], Loss: 0.2542\n",
      "Epoch [99/100], Loss: 0.2556\n",
      "Epoch [100/100], Loss: 0.2551\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "\n",
    "    total_epoch_loss = 0\n",
    "\n",
    "    for batch_features, batch_labels in train_loader:\n",
    "\n",
    "\n",
    "        batch_features, batch_labels = batch_features.to(device), batch_labels.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(batch_features)\n",
    "\n",
    "\n",
    "        loss = criterion(outputs, batch_labels)\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        total_epoch_loss += loss.item()\n",
    "    \n",
    "    avg_epoch_loss = total_epoch_loss / len(train_loader)\n",
    "    \n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {avg_epoch_loss:.4f}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48109188",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9444821428571428\n"
     ]
    }
   ],
   "source": [
    "# Evaluation on train set\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for batch_features, batch_labels in train_loader:\n",
    "        batch_features, batch_labels = batch_features.to(device), batch_labels.to(device)\n",
    "        outputs = model(batch_features)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += batch_labels.shape[0]\n",
    "        correct += (predicted == batch_labels).sum().item()\n",
    "\n",
    "    accuracy = correct / total\n",
    "    print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8f24daf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8946428571428572\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for batch_features, batch_labels in test_loader:\n",
    "        batch_features, batch_labels = batch_features.to(device), batch_labels.to(device)\n",
    "        outputs = model(batch_features)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += batch_labels.shape[0]\n",
    "        correct += (predicted == batch_labels).sum().item()\n",
    "\n",
    "    accuracy = correct / total\n",
    "    print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b4f6def",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
