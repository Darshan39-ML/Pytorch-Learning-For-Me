{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "e29c869b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "6de488d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns in dataframe: ['question', 'answer']\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"/home/darshan39/Downloads/100_Unique_QA_Dataset.csv\")\n",
    "# normalize column names and fill missing question/answer cells\n",
    "df.columns = df.columns.str.strip()\n",
    "if 'Question' in df.columns and 'Answer' in df.columns:\n",
    "    # coerce to string and strip whitespace so tokenizer always receives strings\n",
    "    df['Question'] = df['Question'].fillna('').astype(str).str.strip()\n",
    "    df['Answer'] = df['Answer'].fillna('').astype(str).str.strip()\n",
    "else:\n",
    "    # show columns for debugging if expected columns not present\n",
    "    print('Columns in dataframe:', df.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "fab9a516",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What is the capital of France?</td>\n",
       "      <td>Paris</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What is the capital of Germany?</td>\n",
       "      <td>Berlin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Who wrote 'To Kill a Mockingbird'?</td>\n",
       "      <td>Harper-Lee</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What is the largest planet in our solar system?</td>\n",
       "      <td>Jupiter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What is the boiling point of water in Celsius?</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          question      answer\n",
       "0                   What is the capital of France?       Paris\n",
       "1                  What is the capital of Germany?      Berlin\n",
       "2               Who wrote 'To Kill a Mockingbird'?  Harper-Lee\n",
       "3  What is the largest planet in our solar system?     Jupiter\n",
       "4   What is the boiling point of water in Celsius?         100"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "6e502941",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Robust tokenizer that tolerates non-string inputs\n",
    "import re\n",
    "def tokenize(text):\n",
    "    # ensure we work with a string and remove common punctuation\n",
    "    if text is None:\n",
    "        text = ''\n",
    "    text = str(text)\n",
    "    # replace question marks/apostrophes with space and remove other punctuation\n",
    "    text = text.replace('?', ' ').replace(\"'\", ' ')\n",
    "    text = re.sub(r'[^0-9a-zA-Z\\s]', ' ', text)\n",
    "    return text.lower().strip().split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "297ffe85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['what', 's', 'your', 'name']"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenize(\"What's your name?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "64300864",
   "metadata": {},
   "outputs": [],
   "source": [
    "# vocabulary initialization (ensure single source of truth)\n",
    "vocab = {'<UNK>': 0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "782c1b1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build vocabulary from dataframe rows (robust to missing columns/values)\n",
    "def build_vocab_from_row(row):\n",
    "    # Row can be a Series; extract safely and coerce to string\n",
    "    q_val = row.get('Question', '') if hasattr(row, 'get') else ''\n",
    "    a_val = row.get('Answer', '') if hasattr(row, 'get') else ''\n",
    "    q_text = '' if pd.isna(q_val) else str(q_val).strip()\n",
    "    a_text = '' if pd.isna(a_val) else str(a_val).strip()\n",
    "    q_tokens = tokenize(q_text)\n",
    "    a_tokens = tokenize(a_text)\n",
    "    for token in q_tokens + a_tokens:\n",
    "        if token and token not in vocab:\n",
    "            vocab[token] = len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "28db049c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df.apply placeholder — previous problematic call removed\n"
     ]
    }
   ],
   "source": [
    "# (previous stray df.apply removed) - keep as a placeholder for future checks\n",
    "print('df.apply placeholder — previous problematic call removed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "55e6cc7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab size: 1\n"
     ]
    }
   ],
   "source": [
    "# Build vocab by iterating over dataframe rows\n",
    "for _, row in df.iterrows():\n",
    "    build_vocab_from_row(row)\n",
    "\n",
    "print('Vocab size:', len(vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "810b6ce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_to_indices(text, vocab):\n",
    "    indexed_text = []\n",
    "    for token in tokenize(text):\n",
    "        indexed_text.append(vocab.get(token, vocab.get('<UNK>', 0)))\n",
    "    return indexed_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "888ec8d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0, 0, 0]"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_to_indices(\"What is your name?\", vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ae9d046",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d247747a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick inspection of dataframe to debug tokenization/vocab\n",
    "print('Columns:', df.columns.tolist())\n",
    "print('\\nData sample:')\n",
    "print(df.head(5).to_string(index=False))\n",
    "if 'Question' in df.columns and 'Answer' in df.columns:\n",
    "    print('\\nTypes in Question column:', df['Question'].apply(lambda x: type(x)).value_counts().to_dict())\n",
    "    print('Types in Answer column:', df['Answer'].apply(lambda x: type(x)).value_counts().to_dict())\n",
    "    print('\\nFirst question repr:', repr(df['Question'].iloc[0]))\n",
    "    print('First answer repr:', repr(df['Answer'].iloc[0]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
